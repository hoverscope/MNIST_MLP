{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dcfdd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports numpy, pandas and matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "067eed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset using pandas\n",
    "#df_train for training and df_test for testig purposes\n",
    "df_train  = pd.read_csv('data/dataSet1.csv', header = None)\n",
    "df_test  = pd.read_csv('data/dataSet2.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "92357144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numpy arrays train and test out of pd dataframe for easier data manipulation \n",
    "train = df_train .to_numpy()\n",
    "test = df_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f8f0834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2810, 65)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking array shape for verfication \n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "4c461528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and test data\n",
    "X_train = train[:, :64] #X_train contains all input values wich are the pixel values here\n",
    "Y_train = train[:, 64] #Y_train contains all label/output values wich are the actual numbers\n",
    "\n",
    "#similary this will be test data\n",
    "X_test = test[:, :64]\n",
    "Y_test = test[:, 64]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "25425d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable to control number of neurons in the hidden layer\n",
    "h = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c2cd80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to generate initial values for weights and biases in the network\n",
    "def init_params(h):\n",
    "    W1 = np.random.randn(h, 64) * np.sqrt(2. / (64))\n",
    "    b1 = np.zeros((h, 1))  \n",
    "    W2 = np.random.randn(10, h) * np.sqrt(2. / (h))  \n",
    "    b2 = np.zeros((10, 1))  \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f4325387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineing ReLU function\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0,Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "feca330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineing Sigmoid function\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define softmax function\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))  # Stabilize with max subtraction for numerical stability\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0301d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propogation Function\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X.T) + b1 #input layer dot product with bias added\n",
    "    A1 = ReLU(Z1) #ReLU activation function\n",
    "    Z2 = W2.dot(A1) + b2 #hidden layer dot product with bias added\n",
    "    A2 = softmax(Z2) #sigmoid activation\n",
    "   \n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "47462366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping label to an array\n",
    "#ex: if label is 5 then map the 4th element as 1\n",
    "def one_hot_encode(Y):\n",
    "    l1 = len(Y) #get len of the array\n",
    "    l2 = 10 #10 as the numbers range from 0-9\n",
    "    one_hot_Y = np.zeros((l2, l1), dtype=int)\n",
    "    for i, label in enumerate(Y):\n",
    "        one_hot_Y[label][i] = 1\n",
    "    return one_hot_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "92d97f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#back propgation fucntion for the network to train it\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size  \n",
    "    one_hot_Y = one_hot_encode(Y)  \n",
    "    \n",
    "    dZ2 = A2 - one_hot_Y  # Error for output layer\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)  # Gradient of W2\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True) \n",
    "    \n",
    "    # Backpropagation for the hidden layer (Z1 -> A1)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (A1 > 0) \n",
    "    dW1 = (1 / m) * np.dot(dZ1, X) \n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)  \n",
    "    \n",
    "    return dW1, db1, dW2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9824e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to update the params as we train\n",
    "#alpha is the learning rate\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "64f070cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get predictions\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "15cec39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, Y):\n",
    "    one_hot_Y = one_hot_encode(Y)\n",
    "    accuracy = np.sum(predictions == np.argmax(one_hot_Y, axis=0)) / Y.size *100\n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"True Labels:\", Y)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b057a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, Y_train,iterations, alpha):\n",
    "    W1, b1, W2, b2 = init_params(h)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_train)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X_train, Y_train)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            print(\"Accuracy:\", get_accuracy(get_predictions(A2), Y_train))\n",
    "            \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "2d935ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Predictions: [0 0 0 ... 0 0 8]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 10.569395017793594\n",
      "Iteration: 100\n",
      "Predictions: [0 0 7 ... 2 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 94.02135231316726\n",
      "Iteration: 200\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 96.22775800711743\n",
      "Iteration: 300\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 97.11743772241994\n",
      "Iteration: 400\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 97.50889679715303\n",
      "Iteration: 500\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 97.90035587188612\n",
      "Iteration: 600\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.04270462633453\n",
      "Iteration: 700\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.25622775800711\n",
      "Iteration: 800\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.43416370106762\n",
      "Iteration: 900\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.61209964412811\n",
      "Iteration: 1000\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.68327402135232\n",
      "Iteration: 1100\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Accuracy: 98.96797153024912\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train,1200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "77cd6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, index, W1, b1, W2, b2):\n",
    "    \n",
    "    Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    \n",
    "    predictions = get_predictions(A2)\n",
    "    \n",
    "    predicted_label = predictions[index]\n",
    "    \n",
    "    actual_label = Y[index]\n",
    "    \n",
    "    image_data = X[index, :64].reshape(8, 8)   \n",
    "    \n",
    "    plt.imshow(image_data, cmap='gray')\n",
    "    plt.axis('off')  # Hide the axes for a clean plot\n",
    "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print the predicted and actual labels for the given index\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "    print(f\"Actual Label: {actual_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8868ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATs0lEQVR4nO3cf5BVdfnA8Wd1WVgWJ2hdVJBY2NGcRG1E/SNNNwUVaozSHMUxcWTE8gc2aVNqiT9yakyBgJiyiXVcoNIytdAEXUpxLDOzoaRJZP1Fo1KyjhoR8Pn+wfB8XRfYdQUv5Os1s39w9txzn3sWzvuecw9bVUopAQARsUelBwBg1yEKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKdKuxsTEmTZqUf166dGlUVVXF0qVLKzbT2719Rt6d5ubmaG5urvQYVIAo7OJaWlqiqqoqv/r16xcHHnhgXHTRRfHSSy9Verx3ZNGiRTFt2rRKj7FNK1eujIkTJ8bgwYOjtrY2DjjggLjyyivf9Xafeuqp/NmtXbu219u54YYb4he/+MW7nue98tJLL8WUKVNi6NCh0a9fv2hsbIzzzjuv0mPRjepKD0DPXHvttTFixIhYt25dPPzwwzF37txYtGhRLF++PPr37/+eznLsscfGv//976ipqXlHj1u0aFHMmTNnlwzDn/70p2hubo6hQ4fGl7/85aivr4/nnnsunn/++Xe97dbW1th3333j1VdfjTvuuCMmT57cq+3ccMMNcdppp8WECRPe9Uw72/PPPx9HH310RERccMEFMXTo0Fi9enX8/ve/r/BkdEcUdhPjxo2LI444IiIiJk+eHPX19XHzzTfHXXfdFWeeeeZWH/PGG29EXV3dDp9ljz32iH79+u3w7VbKpk2b4uyzz46DDjoo2traora2dodtu5QSCxYsiIkTJ8aqVati/vz5vY7C7mTKlClRXV0djz32WNTX11d6HN4Bl492U8cff3xERKxatSoiIiZNmhQDBgyIlStXxvjx42OvvfaKs846KyI2H/RmzJgRBx98cPTr1y/22WefmDJlSrz66qudtllKieuvvz7233//6N+/f3ziE5+Iv/zlL12ee1ufKfzud7+L8ePHx6BBg6Kuri4OPfTQmDlzZs43Z86ciIhOl8O22NEzRmy+HLRy5cpu9+X9998fy5cvj6uvvjpqa2vjzTffjI0bN3b7uJ5YtmxZtLe3xxlnnBFnnHFG/Pa3v40XXnihy3qbNm2KmTNnxiGHHBL9+vWLhoaGOPnkk+MPf/hDRGzeZ2+88Ubceuutue+2fIYyadKkaGxs7LLNadOmddrHERHz5s2L448/PgYPHhx9+/aNj3zkIzF37twevZbnnnsuVqxY0e16K1asiHvvvTcuv/zyqK+vj3Xr1sV///vfHj0HledMYTe15WD31ndhGzZsiJNOOimOOeaY+M53vpOXlaZMmRItLS1x7rnnxiWXXBKrVq2K2bNnxxNPPBHLli2LPn36RETEN77xjbj++utj/PjxMX78+PjjH/8YJ554Yqxfv77beRYvXhyf+tSnYr/99oupU6fGvvvuG0899VT88pe/jKlTp8aUKVNi9erVsXjx4rjtttu6PH5nzHjCCSdERER7e/t2Z1+yZElERPTt2zeOOOKIePzxx6OmpiY+85nPxPe+97344Ac/2O3r35b58+dHU1NTHHnkkTFq1Kjo379/LFy4MC6//PJO65133nnR0tIS48aNi8mTJ8eGDRvioYceikcffTSOOOKIuO2222Ly5Mlx1FFHxfnnnx8REU1NTe94nrlz58bBBx8cp5xySlRXV8c999wTX/ziF2PTpk1x4YUXbvexn//85+M3v/lNdPfb9rfsz3322SdOOOGEePDBB2PPPfeMsWPHxty5c7caMHYhhV3avHnzSkSUJUuWlFdeeaU8//zz5cc//nGpr68vtbW15YUXXiillHLOOeeUiChf/epXOz3+oYceKhFR5s+f32n5fffd12n5yy+/XGpqasonP/nJsmnTplzviiuuKBFRzjnnnFzW1tZWIqK0tbWVUkrZsGFDGTFiRBk+fHh59dVXOz3PW7d14YUXlq39ldsZM5ZSyvDhw8vw4cO7PN/bnXLKKSUiSn19fTnrrLPKHXfcUb7+9a+X6urq8rGPfazTc70T69evL/X19eXKK6/MZRMnTiyHHXZYp/UefPDBEhHlkksu6bKNtz53XV1dl9dYyuaf/dZe59VXX91lf7/55ptd1jvppJPKyJEjOy077rjjynHHHddlWU8OGZdccknuz5NPPrn85Cc/KTfeeGMZMGBAaWpqKm+88Ua326ByXD7aTYwZMyYaGhpi2LBhccYZZ8SAAQPizjvvjKFDh3Za7wtf+EKnP99+++3xgQ98IMaOHRtr1qzJr9GjR8eAAQOira0tIja/u1u/fn1cfPHFnS45XHrppd3O9sQTT8SqVavi0ksvjYEDB3b63tsvX2zNzpqxvb2927OEiIjXX389IiKOPPLIaG1tjVNPPTWuvfbauO666+KRRx6JBx54oNttbM29994b//znPzt95nPmmWfGk08+2emS189+9rOoqqqKq6++uss2erL/3om3fl7S0dERa9asieOOOy6eeeaZ6Ojo2O5jly5d2u1ZQsT/78999903fvWrX8Xpp58el112Wdxyyy2xcuXKWLBgwbt7EexUorCbmDNnTixevDja2trir3/9azzzzDNx0kkndVqnuro69t9//07L/v73v0dHR0cMHjw4GhoaOn29/vrr8fLLL0dExLPPPhsREQcccECnxzc0NMSgQYO2O9uWS1mjRo3q1Wt7L2bcni0Hyrd/YD9x4sSIiHjkkUd6td3W1tYYMWJE9O3bN55++ul4+umno6mpKfr37x/z58/P9VauXBlDhgx5V5epemrZsmUxZsyYqKuri4EDB0ZDQ0NcccUVERHdRqGntuzP008/PfbY4/8PMZ/73Oeiurq61/uT94bPFHYTRx11VN59tC19+/bt9I8wYvMHmIMHD+50EHqrhoaGHTZjb1V6xiFDhkTE5mvgbzV48OCIiC4fdvfEa6+9Fvfcc0+sW7euS8QiIhYsWBDf/OY3d8iZwLa28fYPy1euXBknnHBCHHTQQXHzzTfHsGHDoqamJhYtWhTTp0+PTZs2vetZIra9P/fcc8+or6/v1f7kvSMK/+OamppiyZIlcfTRR2/3Vsvhw4dHxOZ37SNHjszlr7zySrf/iLd84Ll8+fIYM2bMNtfb1sHrvZhxe0aPHh233HJLvPjii52Wr169OiJ6F6Wf//znsW7dupg7d27svffenb73t7/9La666qpYtmxZHHPMMdHU1BS//vWv41//+td2zxa2tf8GDRq01f8Ut+XMaot77rkn/vOf/8Tdd98dH/rQh3L5lstzO8ro0aMjIrrsz/Xr18eaNWt2iTcibJvLR//jTj/99Ni4cWNcd911Xb63YcOGPJiMGTMm+vTpE7Nmzep03XjGjBndPsfhhx8eI0aMiBkzZnQ5OL11W1v+z8Tb19lZM/b0ltRPf/rT0bdv35g3b16nd8s//OEPIyJi7Nix3W7j7VpbW2PkyJFxwQUXxGmnndbp67LLLosBAwbkmdGpp54apZS45pprumzn7ftvawf/pqam6OjoiD//+c+57B//+Efceeedndbbc889u2yzo6Mj5s2b16PX1NNbUpubm/PMb926dbm8paUlNm7c2Kv9yXuogh9y0wNb7j567LHHtrveOeecU+rq6rb6vSlTppSIKOPGjSvTp08vs2fPLlOnTi1Dhgwpt99+e673ta99rUREGT9+fJk9e3Y577zzypAhQ8ree++93buPStl8p1CfPn3K8OHDy7Rp08r3v//98qUvfamceOKJuc5Pf/rTEhHl7LPPLq2trWXhwoU7bcZSen73USmlXHvttSUiytixY8ucOXPK+eefX6qqqsqZZ57Zab0tP4958+Ztc1svvvhi2WOPPcqll166zXVOPfXUUl9fX9avX19KKeXss8/O1z9z5swyffr08tnPfrbMmjUrHzN+/PhSV1dXbrrpprJw4cLy6KOPllJKWbNmTamrqysjR44sM2bMKDfccEMZNmxYOfzwwzvdLbRixYpSU1NTDjnkkDJ79uzyrW99qzQ1NZXDDjusRERZtWpVrvtu7j4qpZRbb721REQ58sgjy3e/+91y2WWXlT59+pSPf/zjZcOGDT3aBpUhCru4HRGFUkr5wQ9+UEaPHl1qa2vLXnvtVQ455JDyla98paxevTrX2bhxY7nmmmvKfvvtV2pra0tzc3NZvnx5GT58eLdRKKWUhx9+uIwdO7bstddepa6urhx66KGdDmobNmwoF198cWloaChVVVVdDjA7csZS3lkUNm3aVGbNmlUOPPDA0qdPnzJs2LBy1VVX5UF7i1mzZpWIKPfdd982t3XTTTeViCgPPPDANtdpaWkpEVHuuuuu3Dc33nhjOeigg0pNTU1paGgo48aNK48//ng+ZsWKFeXYY48ttbW1XW7Bvf/++8uoUaNKTU1N+fCHP1xaW1u3ekvq3XffXQ499NDSr1+/0tjYWL797W+XH/3oRzs8CqWUsnDhwnLYYYeVvn37ln322adcdNFF5bXXXuvx46mMqlJ6cI8ZEBGbL3W1t7f7HT78z/JBM/RQKSWWLl0ara2tlR4FdhpnCgAkdx8BkEQBgCQKACRRACD1+O6jHf3bGtm+nvx20l3V9OnTKz1Cr5x77rmVHqFXWlpaKj0Cu4me3FfkTAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEhVpZTSoxWrqnb2LLxFD38su6Qnn3yy0iP0SnNzc6VH6JW1a9dWegR2Ez05rjhTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUnWlB9jZGhsbKz3C+86kSZMqPUKvrF27ttIjQMU5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJCqKz3AzjZw4MBKj/C+s7vu8+bm5kqP0Cvt7e2VHqFXdte5/9c5UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFJ1pQfY2RobGys9wvtOW1tbpUd4X+no6Kj0CL0yYcKESo/Qa0uXLq30CDuNMwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBVV3qAnW3t2rWVHuF959xzz630CL3S3t5e6RF65aMf/WilR+iVtra2So/Qa4MGDar0CDuNMwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACBVV3qAnW3p0qWVHuF9p7GxsdIj9Ep7e3ulR+iVCRMmVHqEXuno6Kj0CL02cODASo+w0zhTACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkKpKKaVHK1ZV7exZeItJkyZVeoRemzdvXqVHeF959tlnKz1Cr0ybNq3SI/RaS0tLpUfolZ4c7p0pAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIAqaqUUio9BAC7BmcKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKAKT/AwA7rkVFg1b7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 91\n",
      "Predicted Label: 6\n",
      "Actual Label: 6\n"
     ]
    }
   ],
   "source": [
    "index = 91\n",
    "\n",
    "predict(X_test, Y_test, index, W1, b1, W2, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2736cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Training Data:\n",
      "Predictions: [0 0 7 ... 8 1 7]\n",
      "True Labels: [0 0 7 ... 8 1 7]\n",
      "Training Accuracy: 99.15%\n",
      "\n",
      "Evaluating on Test Data:\n",
      "Predictions: [0 2 5 ... 8 9 8]\n",
      "True Labels: [0 2 5 ... 8 9 8]\n",
      "Test Accuracy: 96.30%\n",
      "\n",
      "The model does not appear to be overfitting.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X, Y, W1, b1, W2, b2):\n",
    "   \n",
    "    Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    accuracy = get_accuracy(predictions, Y)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate on training data\n",
    "print(\"Evaluating on Training Data:\")\n",
    "train_accuracy = evaluate_model(X_train, Y_train, W1, b1, W2, b2)\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate on test data\n",
    "print(\"\\nEvaluating on Test Data:\")\n",
    "test_accuracy = evaluate_model(X_test, Y_test, W1, b1, W2, b2)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Check for overfitting\n",
    "if train_accuracy > test_accuracy + 10:  # Arbitrary threshold (10%) to indicate overfitting\n",
    "    print(\"\\nThe model may be overfitting.\")\n",
    "else:\n",
    "    print(\"\\nThe model does not appear to be overfitting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdfef14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
