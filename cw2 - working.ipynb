{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfdd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports numpy, pandas and matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067eed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset using pandas\n",
    "#df_train for training and df_test for testig purposes\n",
    "df_train  = pd.read_csv('data/dataSet1.csv', header = None)\n",
    "df_test  = pd.read_csv('data/dataSet2.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92357144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numpy arrays train and test out of pd dataframe for easier data manipulation \n",
    "train = df_train.to_numpy()\n",
    "test = df_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f0834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2810, 65)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking array shape for verfication \n",
    "train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c461528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and test data\n",
    "X_train = train[:, :64] #X_train contains all input values wich are the pixel values here\n",
    "Y_train = train[:, 64] #Y_train contains all label/output values wich are the actual numbers\n",
    "\n",
    "\n",
    "#similary this will be test data\n",
    "X_test = test[:, :64]\n",
    "Y_test = test[:, 64]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25425d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining hyperparameters \n",
    "\n",
    "#h is the number of neurons in the hidden layer\n",
    "#training_cycles is number of cycles\n",
    "#learning_rate is to control the models learning rate\n",
    "\n",
    "h = 180\n",
    "training_cycles = 8000\n",
    "learning_rate = 0.009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2cd80ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to initialize parameters using the He initialization\n",
    "\n",
    "def init_params(h):\n",
    "    w1 = np.random.randn(h, 64) * np.sqrt(2. / (64))  # He initialization\n",
    "    b1 = np.zeros((h, 1))  \n",
    "    w2 = np.random.randn(10, h) * np.sqrt(2. / (h))  # He initialization\n",
    "    b2 = np.zeros((10, 1))  \n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feca330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineing Sigmoid function\n",
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b1f4719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineing Leaky ReLU function\n",
    "def LeakyReLU(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, Z, alpha * Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0301d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Propogation Function\n",
    "\n",
    "def feed_forward(w1, b1, w2, b2, X):\n",
    "    Z1 = w1.dot(X.T) + b1 #input layer dot product with bias added\n",
    "    A1 = LeakyReLU(Z1) #ReLU activation function\n",
    "    Z2 = w2.dot(A1) + b2 #hidden layer dot product with bias added\n",
    "    A2 = sigmoid(Z2) #sigmoid activation\n",
    "   \n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47462366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping label to an array\n",
    "#ex: if label is 5 then map the 4th element as 1\n",
    "\n",
    "def map_labels(Y):\n",
    "    l1 = len(Y) #get len of the array\n",
    "    l2 = 10 #10 as the numbers range from 0-9\n",
    "    mapped_label = np.zeros((l2, l1), dtype=int)\n",
    "    for i, label in enumerate(Y):\n",
    "        mapped_label[label][i] = 1\n",
    "    return mapped_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d97f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation for the sigmoid output\n",
    "\n",
    "def back_prop(Z1, A1, Z2, A2, w2, X, Y):\n",
    "    m = Y.size\n",
    "    mapped_label = map_labels(Y)\n",
    "    \n",
    "    dZ2 = A2 - mapped_label  # Error for output layer with sigmoid\n",
    "    dw2 = (1 / m) * np.dot(dZ2, A1.T)  # Gradient for w2\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Backpropagation for the hidden layer (Z1 -> A1)\n",
    "    dZ1 = np.dot(w2.T, dZ2) * (A1 > 0)  # Derivative of ReLU\n",
    "    dw1 = (1 / m) * np.dot(dZ1, X)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    return dw1, db1, dw2, db2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9824e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to update the params as we train\n",
    "#alpha is the learning rate\n",
    "\n",
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return w1, b1, w2, b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f070cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get predictions\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15cec39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get accuracy of predicted data\n",
    "def get_accuracy(predictions, Y):\n",
    "    mapped_label = map_labels(Y)\n",
    "    accuracy = np.sum(predictions == np.argmax(mapped_label, axis=0)) / Y.size *100\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec946dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to evaluate model, to be used on test data\n",
    "def model_eval(X, Y, w1, b1, w2, b2):\n",
    "\n",
    "    Z1, A1, Z2, A2 = feed_forward(w1, b1, w2, b2, X)  \n",
    "    predictions = get_predictions(A2)                \n",
    "    accuracy = get_accuracy(predictions, Y)          \n",
    "    print(f\"Accuracy on Test Data: {accuracy:.2f}%\")  \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7149c328",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_until_98_with_rmsprop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_w1, best_b1, best_w2, best_b2\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Execute with RMSprop optimization and increased iterations for further tuning\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m best_w1, best_b1, best_w2, best_b2 \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_until_98_with_rmsprop\u001b[49m(\n\u001b[0;32m     75\u001b[0m     X_train, Y_train, X_test, Y_test, \n\u001b[0;32m     76\u001b[0m     max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m, \n\u001b[0;32m     77\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.009\u001b[39m\n\u001b[0;32m     78\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_until_98_with_rmsprop' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(X_train, Y_train, X_test, Y_test, max_iterations=10000, initial_learning_rate=0.009):\n",
    "    # Initialize parameters\n",
    "    w1, b1, w2, b2 = init_params(h)  # Ensure h is your hidden layer size\n",
    "    \n",
    "    # RMSprop parameters\n",
    "    epsilon = 1e-8\n",
    "    weight_decay = 1e-4  # L2 regularization\n",
    "    \n",
    "    # RMSprop specific variables\n",
    "    cache_w1, cache_b1, cache_w2, cache_b2 = np.zeros_like(w1), np.zeros_like(b1), np.zeros_like(w2), np.zeros_like(b2)\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    patience = 10\n",
    "    no_improve_counter = 0\n",
    "    \n",
    "    best_w1, best_b1, best_w2, best_b2 = w1.copy(), b1.copy(), w2.copy(), b2.copy()  \n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Dynamic learning rate adjustment\n",
    "        lr = initial_learning_rate * (0.99 ** (iteration // 500))\n",
    "        \n",
    "        # Forward and backward pass\n",
    "        Z1, A1, Z2, A2 = feed_forward(w1, b1, w2, b2, X_train)\n",
    "        dw1, db1, dw2, db2 = back_prop(Z1, A1, Z2, A2, w2, X_train, Y_train)\n",
    "        \n",
    "        # Add weight decay (L2 regularization)\n",
    "        dw1 += weight_decay * w1\n",
    "        dw2 += weight_decay * w2\n",
    "        \n",
    "        # RMSprop optimization with squared gradients\n",
    "        cache_w1 = 0.9 * cache_w1 + 0.1 * (dw1 ** 2)\n",
    "        cache_b1 = 0.9 * cache_b1 + 0.1 * (db1 ** 2)\n",
    "        cache_w2 = 0.9 * cache_w2 + 0.1 * (dw2 ** 2)\n",
    "        cache_b2 = 0.9 * cache_b2 + 0.1 * (db2 ** 2)\n",
    "        \n",
    "        # Parameter updates with RMSprop\n",
    "        w1 -= lr * dw1 / (np.sqrt(cache_w1) + epsilon)\n",
    "        b1 -= lr * db1 / (np.sqrt(cache_b1) + epsilon)\n",
    "        w2 -= lr * dw2 / (np.sqrt(cache_w2) + epsilon)\n",
    "        b2 -= lr * db2 / (np.sqrt(cache_b2) + epsilon)\n",
    "        \n",
    "        # Periodic evaluation every 100 iterations\n",
    "        if iteration % 100 == 0:\n",
    "            Z1_test, A1_test, Z2_test, A2_test = feed_forward(w1, b1, w2, b2, X_test)\n",
    "            test_predictions = get_predictions(A2_test)\n",
    "            test_accuracy = get_accuracy(test_predictions, Y_test)\n",
    "            \n",
    "            print(f\"Iteration {iteration}: Test Accuracy {test_accuracy:.2f}% | Learning rate: {lr:.6f} | Weight Decay: {weight_decay:.6f}\")\n",
    "            \n",
    "            # Update best accuracy and monitor no improvement\n",
    "            if test_accuracy > best_accuracy:\n",
    "                best_accuracy = test_accuracy\n",
    "                best_w1, best_b1, best_w2, best_b2 = w1.copy(), b1.copy(), w2.copy(), b2.copy()  # Save the best model\n",
    "                no_improve_counter = 0\n",
    "            else:\n",
    "                no_improve_counter += 1\n",
    "            \n",
    "            # If we reach 98% accuracy, stop\n",
    "            if test_accuracy >= 98.4:\n",
    "                print(f\"Achieved target accuracy of 98% at iteration {iteration}.\")\n",
    "                break\n",
    "            \n",
    "            # If no improvement after 'patience' iterations, adjust hyperparameters\n",
    "            if no_improve_counter > patience:\n",
    "                print(f\"No improvement for {patience} iterations. Adjusting hyperparameters...\")\n",
    "                weight_decay *= 0.5  # Decrease weight decay to allow for more complex models\n",
    "                initial_learning_rate *= 0.9  # Reduce learning rate for finer updates\n",
    "                no_improve_counter = 0  # Reset the counter\n",
    "    \n",
    "    # Once training is over, return the best model\n",
    "    return best_w1, best_b1, best_w2, best_b2\n",
    "\n",
    "# Execute with RMSprop optimization and increased iterations for further tuning\n",
    "best_w1, best_b1, best_w2, best_b2 = train_until_98_with_rmsprop(\n",
    "    X_train, Y_train, X_test, Y_test, \n",
    "    max_iterations=20000, \n",
    "    initial_learning_rate=0.009\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d874a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_eval(X_test, Y_test, best_w1, best_b1, best_w2, best_b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd460daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deedf114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b4672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e6fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
